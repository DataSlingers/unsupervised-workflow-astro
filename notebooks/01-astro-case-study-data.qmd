---
title: "Finding Common Origins of Milky Way Stars"
date: today
author: "Andersen Chang$^*$, Tiffany M. Tang$^*$, Tarek M. Zikry$^*$, Genevera I. Allen"
format:
  html:
    code-fold: show
---

```{r}
#| include: false

rm(list = ls())

# source all functions from R/ folder
for (fname in list.files(here::here("R"), pattern = "*.R")) {
  source(here::here(file.path("R", fname)))
}

# helper paths
DATA_PATH <- here::here("data")
RESULTS_PATH <- here::here("results")
if (!file.exists(RESULTS_PATH)) {
  dir.create(RESULTS_PATH, recursive = TRUE)
}

# helpers for quarto plotting
subchunkify <- purrr::partial(subchunkify, prefix = "data")
subchunk_idx <- 1  # for subchunk numbering

set.seed(12345)
```

## Loading, Cleaning, and Splitting Data

Let us begin by loading in the APOGEE DR17 data, which was originally downloaded from [SDSS](https://www.sdss4.org/dr17/irspec/spectro_data/) (or direct download link [here](https://data.sdss.org/sas/dr17/apogee/spectro/aspcap/dr17/synspec_rev1/allStar-dr17-synspec_rev1.fits)).
A detailed data dictionary can be found [here](https://data.sdss.org/datamodel/files/APOGEE_ASPCAP/APRED_VERS/ASPCAP_VERS/allStar.html).

```{r}
# Load data
data_orig <- load_astro_data(data_dir = DATA_PATH)
```

This data contains the chemical abundances from 19 different elements as well as metadata about the quality control and star properties. 
Here, we have also supplemented the data with the APOGEE DR17 value-added catalog of globular clusters (GCs) [@schiavon2024apogee]. 
GCs are sites of dense star formation, comprised of $10^5 - 10^7$ stars that were roughly formed around the same time. 
GCs hence provide a convenient starting point for understanding and assessing the chemical origins of stars in the Milky Way.
Nonetheless, this is only a starting point --- we note that many stars in the APOGEE survey have been assigned to GCs based on proximity while there is also the broader open question of discovering deeper shared origins of possibly distant bodies.

We next perform some basic quality control filtering. 
Specifically, following previous literature [@pagnini2025abundance], we subset the stars to those that meet the criteria below:

- Signal-to-noise (S/N) ratio threshold greater than 70
- Effective temperature $T_{eff}$ ranges between 3500 and 5500
- Logarithm of the surface gravity $\log g$ less than 3.6
- GC membership probability greater than 0.9
- STARFLAG parameter (indicating poor quality measurements) is set to 0

This quality control filtering resulted in a sample of 3,286 observations (or stars). We will investigate alternative, but equally-reasonable quality control filtering choices in a future section.

```{r}
# QC filtering choices
SNR_THRESHOLD <- 70
MIN_TEFF_THRESHOLD <- 3500
MAX_TEFF_THRESHOLD <- 5500
LOGG_THRESHOLD <- 3.6
STARFLAG <- 0
VB_THRESHOLD <- 0.9

# Apply QC filter
data_qc_filtered <- apply_qc_filtering(
  data_orig,
  snr_threshold = SNR_THRESHOLD,
  teff_thresholds = c(MIN_TEFF_THRESHOLD, MAX_TEFF_THRESHOLD),
  logg_threshold = LOGG_THRESHOLD,
  starflag = STARFLAG,
  vb_threshold = VB_THRESHOLD
)
```

Below, we provide a quick overview of the data after quality control filtering.

:::{.panel-tabset}

### Abundance Data

```{r}
#| output: asis
#| code-fold: true

abundance_df <- data_qc_filtered$abundance
skimr::skim(abundance_df)
```

### Metadata

```{r}
#| output: asis
#| code-fold: true

metadata_df <- data_qc_filtered$meta |> 
  dplyr::mutate(
    dplyr::across(where(is.character), as.factor)
  )
skimr::skim(metadata_df)
```

### GC Frequency Table

```{r}
#| output: asis
#| code-fold: true

data_qc_filtered$meta |> 
  dplyr::group_by(GC_NAME) |> 
  dplyr::summarise(
    n = dplyr::n(),
    .groups = "drop"
  ) |> 
  dplyr::arrange(dplyr::desc(n)) |>
  vthemes::pretty_DT()
```

:::

Before proceeding any further, we randomly split the data into training and test using an 80-20% split. This led to a training set of 2,628 observations and a test set of 658 observations. 

```{r}
# Split data into training and test sets
TRAIN_PROP <- 0.8

train_idxs <- sample(
  1:nrow(data_qc_filtered$abundance), 
  size = round(TRAIN_PROP * nrow(data_qc_filtered$abundance)),
  replace = FALSE
)
train_data <- data_qc_filtered$abundance[train_idxs, ]
test_data <- data_qc_filtered$abundance[-train_idxs, ]
train_metadata <- data_qc_filtered$meta[train_idxs, ]
test_metadata <- data_qc_filtered$meta[-train_idxs, ]
```

We next impute missing abundance values in the data and standardize each elemental abundance feature to have mean 0 and standard deviation 1. Given that there are various ways to perform missing data imputation, we implement two different imputation methods: (1) mean imputation and (2) random forest imputation using MissForest [@stekhoven2012missforest].

```{r}
# impute missing values and standardize data
data_fpath <- file.path(DATA_PATH, "astro_cleaned_data.RData")
if (!file.exists(data_fpath)) {  # if not already cached
  metadata <- list(
    train = train_metadata,
    test = test_metadata
  )
  
  data_mean_imputed <- clean_astro_data(
    train_data = train_data,
    test_data = test_data,
    impute_mode = "mean"
  )
  
  data_rf_imputed <- clean_astro_data(
    train_data = train_data,
    test_data = test_data,
    impute_mode = "rf"
  )
  
  save(
    metadata, data_mean_imputed, data_rf_imputed, 
    file = file.path(DATA_PATH, "astro_cleaned_data.RData")
  )
} else {  # read from cache
  load(data_fpath)
}
```
